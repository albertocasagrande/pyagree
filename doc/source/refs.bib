@article{bennettS,
    author = {Bennett, E.M. and Alpert, R. and Goldsein, A.C.},
    title = "{Communications Through Limited-Response Questioning}",
    journal = {Public Opinion Quarterly},
    volume = {18},
    number = {3},
    pages = {303--308},
    year = {1954},
    month = {01},
    abstract = "{The extent of consistency between information from two methods of communication, the interview and the limited-response question, was investigated. Thirty questions showed consistencies greater than could be expected on the basis of chance. The questions were classified into four general categories, and the mean coefficients of consistency for these categories ranged from 0.46 to 1.00.}",
    issn = {0033-362X},
    doi = {10.1086/266520},
}

@article{bennettS2,
title = {The effect of combining categories on Bennett, Alpert and Goldstein’s S},
journal = "Statistical Methodology",
volume = "9",
number = "3",
pages = "341--352",
year = "2012",
issn = "1572-3127",
doi = {10.1016/j.stamet.2011.09.001},
author = "Matthijs J. Warrens",
keywords = "Interrater reliability, Nominal agreement, Merging categories, Bennett, Alpert and Goldstein’s , Brennan and Prediger’s , Janson and Vegelius’ , Janes’ RE, Cohen’s kappa, Cauchy–Schwarz inequality",
abstract = "Cohen’s kappa is the most widely used descriptive measure of interrater agreement on a nominal scale. A measure that has repeatedly been proposed in the literature as an alternative to Cohen’s kappa is Bennett, Alpert and Goldstein’s S. The latter measure is equivalent to Janson and Vegelius’ C and Brennan and Prediger’s kappan. An agreement table can be collapsed into a table of smaller size by partitioning categories into subsets. The paper presents several results on how the overall S-value is related to the S-values of the collapsed tables. It is shown that, if the categories are partitioned into subsets of the same size and if we consider all collapsed tables of this partition type, then the overall S-value is equivalent to the average S-value of the collapsed tables. This result illustrates that there are types of partitioning the categories that, on average, do not result in loss of information in terms of the S-value. In addition, it is proved that for all other partition types, the overall S-value is strictly smaller than the average S-value of the collapsed tables. A consequence is that there is always at least one way to combine categories such that the S-value increases. The S-value increases if we combine categories on which there exists considerable disagreement."
}

@article{CohenK,
author = {Cohen, Jacob},
title ={A Coefficient of Agreement for Nominal Scales},
journal = {Educational and Psychological Measurement},
volume = {20},
number = {1},
pages = {37--46},
year = {1960},
doi = {10.1177/001316446002000104}
}

@article{fleissK,
  author = {Fleiss, Joseph L.},
  journal = {Psychological Bulletin},
  keywords = {inter-rater measure reliability},
  number = 5,
  pages = {378--382},
  timestamp = {2010-05-04T08:55:49.000+0200},
  title = {{Measuring nominal scale agreement among many raters}},
  doi = {10.1037/h0031619},
  volume = 76,
  year = 1971
}

@article{ScottPi,
 ISSN = {0033362X, 15375331},
 doi = {10.1086/266577},
 author = {William A. Scott},
 journal = {The Public Opinion Quarterly},
 number = {3},
 pages = {321--325},
 publisher = {[Oxford University Press, American Association for Public Opinion Research]},
 title = {Reliability of Content Analysis: The Case of Nominal Scale Coding},
 volume = {19},
 year = {1955}
}

@article{BangdiwalaB,
	author = { Munoz, Sergio R.  and  Bangdiwala, Shrikant I.},
	title = {{Interpretation of Kappa and B statistics measures of agreement}},
	journal = {Journal of Applied Statistics},
	volume = {24},
	number = {1},
	pages = {105--112},
	year  = {1997},
	publisher = {Taylor & Francis},
	doi = {10.1080/02664769723918}
}

@unpublished{IAe2020,
author = {Casagrande, Alberto and Fabris, Francesco and Girometti, Rossano},
title = {{Extending Information Agreement by Continuity}},
year = {2020},
note = {}
}

@unpublished{IA2020,
author = {Casagrande, Alberto and Fabris, Francesco and Girometti, Rossano},
title = {{Beyond Kappa: An Informational Index for
Diagnostic Agreement in Dichotomous and
Multivalue Ordered-Categorical Ratings}},
journal = {Medical & Biological Engineering & Computing},
year = {2020},
note = {}
}

@article{YuleY,
 ISSN = {09528385},
 author = {Yule, George Udny},
 journal = {Journal of the Royal Statistical Society},
 number = {6},
 pages = {579--652},
 publisher = {[Wiley, Royal Statistical Society]},
 title = {On the Methods of Measuring Association Between Two Attributes},
 volume = {75},
 year = {1912},
 doi = {10.2307/2340126}
}
